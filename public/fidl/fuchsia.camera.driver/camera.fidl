// Copyright 2018 The Fuchsia Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

library fuchsia.camera.driver;

enum CaptureType {
  INVALID = 0;
  STILL_IMAGE = 1;       // The source will provide on image.
  BURST  = 2;              // The source will provide a set of images.
  STREAM = 3;              // The source will be continuously providing frames
                           // until signalled to stop.
};

// This pixel type is a stand-in for the pixel_format that will be defined in
// the buffer collections.
enum PixelFormat {
  INVALID = 0;      // default value, not supported
  RGB32 = 1;        // 32bpp BGRA, 1 plane.
  I420 = 2;
  M420 = 3;
  NV12 = 4;
  YUY2 = 5;
  MJPEG = 6;
};

// A structure used along with the CAMERA_STREAM_CMD_GET_FORMATS command
// in order to describe the formats supported by a video stream.
struct VideoFormat {
  CaptureType capture_type;
  // The width, in pixels, of the decoded video.
  uint16 width;
  // The height, in pixels, of the decoded video.
  uint16 height;
  // The number of bytes per line of video.
  uint32 stride;
  // The number of bits per pixel used to specify color in the decoded video.
  uint8 bits_per_pixel;
  PixelFormat pixel_format;
  // The frame rate is frames_per_sec_numerator / frames_per_sec_denominator.
  uint32 frames_per_sec_numerator;
  uint32 frames_per_sec_denominator;
};

// Status to be set when a frame is signalled available.
enum FrameStatus {
  OK = 0;
  // An error occurred during the production of a frame.
  // No data will be available in the data buffer corresponding to this
  // notification.
  ERROR_FRAME = 1;

  // No space was available in the data buffer, resulting in a dropped frame.
  ERROR_BUFFER_FULL = 2;
};

// Sent by the driver to the client when a frame is available for processing,
// or an error occurred.
struct FrameAvailableEvent {
  // Non zero if an error occurred.
  FrameStatus frame_status;

  // Number of bytes in the frame.
  uint32 size;

  // The position (in bytes) of the start of the frame in the data buffer.
  uint64 offset;

  // TODO(garratt): Add metadata.
};

// These are the original interfaces, which are being used for compatibility.
// The names are preserved from the ones in camera.h for porting ease.
[Discoverable]
interface Stream {
  // Get the available format types for this device
  1: GetFormats() -> (vector<VideoFormat> formats);

  // Sent by the client to indicate desired stream characteristics.
  // If setting the format is successful, the stream request will be honored.
  2: SetFormats(VideoFormat format, request<VideoBuffer> stream) -> (uint32 max_frame_size);
};

interface VideoBuffer {
  // NOTE: The client must transfer a VMO handle for the data buffer
  // with read-write permissions. The size of the VMO should be an
  // integral multiple of max_frame_size returned in SET_FORMAT.
  1: SetBuffer(handle<vmo> buffer);

  // Starts the streaming of frames.
  2: Start();

  // Stops the streaming of frames.
  3: Stop();

  // Unlocks the specified frame, allowing the driver to reuse the memory.
  4: FrameRelease(uint64 data_offset);

  // Sent by the driver to the client when a frame is available for processing,
  // or an error occurred.
  5: -> OnFrameAvailable(FrameAvailableEvent frame);
};
