// Copyright 2018 The Fuchsia Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

library fuchsia.camera.driver;

enum CaptureType {
  INVALID = 0;
  STILL_IMAGE = 1;       // The source will provide on image.
  BURST  = 2;            // The source will provide a set of images.
  STREAM = 3;            // The source will be continuously providing frames
                         // until signalled to stop.
};

// This pixel type is a stand-in for the pixel_format that will be defined in
// the buffer collections.
enum PixelFormat {
  INVALID = 0;      // default value, not supported
  RGB32 = 1;        // 32bpp BGRA, 1 plane.
  I420 = 2;
  M420 = 3;
  NV12 = 4;
  YUY2 = 5;
  MJPEG = 6;
};

// A structure used along with the GetFormats command
// to describe the formats supported by a video stream.
struct VideoFormat {
  CaptureType capture_type;
  // The width, in pixels, of the decoded video.
  uint32 width;
  // The height, in pixels, of the decoded video.
  uint32 height;
  // The number of bytes per line of video.
  uint32 stride;
  // The number of bits per pixel used to specify color in the decoded video.
  uint8 bits_per_pixel;
  PixelFormat pixel_format;
  // The frame rate is frames_per_sec_numerator / frames_per_sec_denominator.
  uint32 frames_per_sec_numerator;
  uint32 frames_per_sec_denominator;
};

const uint32 MAX_FORMATS_PER_RESPONSE = 16;

// Status to be set when a frame is signalled available.
enum FrameStatus {
  OK = 0;
  // An error occurred during the production of a frame.
  // No data will be available in the data buffer corresponding to this
  // notification.
  ERROR_FRAME = 1;

  // No space was available in the data buffer, resulting in a dropped frame.
  ERROR_BUFFER_FULL = 2;
};

struct Metadata {
    int64 timestamp;
};

// Sent by the driver to the client when a frame is available for processing,
// or an error occurred.
struct FrameAvailableEvent {
  // Non zero if an error occurred.
  FrameStatus frame_status;

  // Number of bytes in the frame.
  uint32 frame_size;

  // The position (in bytes) of the start of the frame in the data buffer.
  uint64 frame_offset;

  Metadata metadata;
};

// These are the original interfaces, which are being used for compatibility.
// The names are preserved from the ones in camera.h for porting ease.
[Discoverable]
interface Control {
  // Get the available format types for this device
  // NOTE: The formats are paginated to MAX_FORMATS_PER_RESPONSE, multiple GetFormats
  //       need to be issued until total_format_count are received
  1: GetFormats(uint32 index) -> (vector<VideoFormat> formats, uint32 total_format_count, zx.status status);

  // Sent by the client to indicate desired stream characteristics.
  // If setting the format is successful, the stream request will be honored.
  2: SetFormat(VideoFormat format,
               request<Stream> stream,
               request<StreamEvents> stream_events) -> (uint32 max_frame_size, zx.status status);
};

interface StreamEvents {
  // Sent by the driver to the client when a frame is available for processing,
  // or an error occurred.
  1: -> OnFrameAvailable(FrameAvailableEvent frame);

  // Frame streaming stopped
  2: -> Stopped();
};

interface Stream {
  // Set buffer storage used by camera capture.
  // NOTE: The client must transfer a VMO handle for the data buffer
  // with read-write permissions. The size of the VMO should be an
  // integral multiple of max_frame_size returned in SET_FORMAT.
  1: SetBuffer(handle<vmo> buffer) -> (zx.status status);

  // Starts the streaming of frames.
  2: Start() -> (zx.status status);

  // Stops the streaming of frames.
  3: Stop() -> (zx.status status);

  // Unlocks the specified frame, allowing the driver to reuse the memory.
  4: ReleaseFrame(uint64 data_offset) -> (zx.status status);
};
